---
title: "Bayes A"
author: 
  - Costa, W. G.^[Weverton Gomes da Costa, Pós-Doutorando, Embrapa Mandioca e Fruticultura, wevertonufv@gmail.com]
date: "`r Sys.Date()`"
site: workflowr::wflow_site
url: https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava
output:
  workflowr::wflow_html:
    toc: TRUE
editor_options:
  chunk_output_type: console
---

## Configurations and packages

```{r setup, include=F} 
knitr::opts_chunk$set(echo = T, warning = F)
```

To perform the analyses, we will need the following packages:

```{r libraries, message=FALSE}
library(furrr)
library(tidyverse)
library(cvTools)
library(kableExtra)
library(BGLR)
```

## Data

```{r data}
geno<- readRDS("data/geno.rds")
pheno<-readRDS("data/pheno.rds")
traits <- colnames(pheno)[-1]
```

## Bayes A

We can perform the Ridge Regression in the Bayesian framework. For this purpose, we will use the [BGLR](https://github.com/gdlc/BGLR-R) package [@BGLR]. In this package, we will need an element called "ETA". In the ETA, we will set the linear predictors of the model and the priors.

### Cross-validation 

To prove that the prediction is accurate, we should perform a cross-validation (CV) scheme. For this purpose, we divide the data into a training set and a validation set. 

First we separate the data into *k* folds. Then, we attribute *NA* for one fold and try to predict the data from this fold based on the others. When selecting the number of folds, one must prioritize the balance between the number of observations in each fold. 

In addition, this process should be repeated for further validation. The step-by-step below will guide the CV in the data we are analysing.

####  1. Determine the number of folds and repetitions

```{r nfolds-nrep}
nfolds = 5
nrept = 5
```

Since we defined 5 folds, our data will be divided into 5 parts with 83 observations each.

#### 2. Match the order of the data and the rows of the SNP matrix

The order is decreasing or increasing (numeric or alphabetical) regarding the name of the genotypes.

```{r order-data}
pheno <- pheno[order(pheno$ID_Clone, decreasing = F),]
geno <- geno[order(row.names(geno)),]
all(rownames(geno) == pheno$ID_Clone)
```

#### 3. Add a column indicating a number for each observation

This will be useful to assign each observation for a fold, which will be the next step.

```{r add-column}
pheno$ID <- factor(1:nrow(pheno))
```

#### 4. Folds assignment

In this step, we will assign each observation to a fold. Bear in mind that for each repetition, the folds will comprise different observations. The purpose of the repetition is to make sure of the randomness of the assignment step. 

In this step, we will use the [cvTools](https://cran.r-project.org/web/packages/cvTools/cvTools.pdf) package [@cvTools]

For better performance, we included this step in the loop of the next step.

### Run model

The next step is the very CV. Here, we will define the linear predictor and the lists that will be useful in the loop. The first list, here called results_cv_BayesA and, contains the results for each fold assignation that we built in the previous step. The second GEBVS_BayesA contains the GEBVs.

Then, we will construct the loop. Each iteration will assign *NA* for a different fold, and we will use the other folds to predict the missing values. Note that the folds vary for each repetition and trait.

Set up parallel processing. Define and run multiple models to get the GEBVs *ATTENTION: This process is time-consuming.*

```{r BayesA}
# Planejar o processamento em várias sessões para paralelização
plan(multisession)

# Iniciar uma lista para armazenar os resultados
results_list <-
  future_map(traits, .options = furrr_options(seed = 100), function(j)  {
    # Pré-processamento dos dados
    pheno2 <- pheno %>%
      select(ID_Clone, all_of(j)) %>%
      na.omit() %>%
      ungroup() %>%
      filter(ID_Clone %in% rownames(geno)) %>%
      mutate(ID = factor(1:nrow(.))) %>%
      droplevels()
    
    # Filtrar as linhas de Z com base em pheno2$ID_Clone
    ETA = list(list(X = geno[rownames(geno) %in% pheno2$ID_Clone, ], model = "BayesA"))
    
    #Semente para reprodução
    set.seed(100)
    
    # Listas das folds
    fold.list <- lapply(1:nrept, function(a) {
      folds <- cvFolds(nlevels(pheno2$ID),
                       type = "random",
                       K = nfolds)
      
      split(folds$subsets, f = folds$which)
    })
    
    # Usar future_map_dfr para criar dobras cruzadas em paralelo
    future_map_dfr(1:length(fold.list), function(z) {
      for (i in 1:nfolds) {
        # Conjunto de treinamento
        train_data <- pheno2
        
        # Conjunto de validação
        train_data[train_data$ID %in% fold.list[[z]][[i]], j] <- NA
        
        # Fitting model
        CV_M <-
          BGLR(
            y = train_data[[j]],
            ETA = ETA,
            nIter = 20000,
            burnIn = 5000,
            thin = 5,
            verbose = F,
            saveAt = "output/BayesA_"
          )
        
        # GEBV
        Pred <-
          data.frame(
            Yhat = CV_M$yHat,
            ID = train_data$ID,
            ID_Clone = train_data$ID_Clone
          ) %>%
          filter(ID %in% fold.list[[z]][[i]])
        
        result1 <-
          tibble(
            GEBV = Pred$Yhat,
            ID = Pred$ID,
            ID_Clone = Pred$ID_Clone,
            Trait = j,
            rep = z,
            fold = i
          )
        
        # Resultados da previsão
        if (i == 1) {
          result <- result1
        } else {
          result <- rbind(result, result1)
        }
      }
      
      #Ordenando os resultados de acordo com o ID
      result <- result[order(result$ID, decreasing = F),]
      
      # Resultados da validação cruzada
      result_cv <- tibble(
        Trait = j,
        rep = z,
        Log = all(result$ID == pheno2$ID),
        Ac = round(cor(result$GEBV, pheno2[[j]], use = "na.or.complete"), 3),
        MSPE = round(mean((
          result$GEBV - pheno2[[j]]
        ) ^ 2, na.rm = TRUE), 3),
        result = list(result)
      )
    })
  })

# Combinar todos os resultados da validação cruzada em uma única estrutura
results_cv_BayesA <- do.call(rbind, results_list)

# Extrair os GEBVs (Valores Genômicos Empíricos Melhorados) em uma estrutura separada
GEBVS_BayesA <- do.call(rbind, results_cv_BayesA$result)
```

### Results

The object "GEBVS_BayesA" contains the GEBVs for each trait and clone. The table above shows the first five clones and their GEBVs for each trait.

```{r GEBVS_BayesA}
GEBVS_BayesA |>
  group_by(Trait, ID_Clone) |>
  summarise(GEBV = mean(GEBV)) %>%
  pivot_wider(names_from = Trait, values_from = GEBV) %>%
  head() %>%
  kbl(escape = F, align = 'c') |>
  kable_classic("hover", full_width = F, position = "center", fixed_thead = T)
```

```{r save-GEBVS_BayesA,  include=FALSE}
saveRDS(GEBVS_BayesA, "output/GEBVS_BayesA.RDS")
```

Acuracy and MSPE for each trait and repetition:

```{r results_cv_BayesA}
results_cv_BayesA[-6] |>
  group_by(Trait) %>% 
  summarise_all(mean) %>% 
  arrange(desc(Ac), MSPE) %>% 
  kbl(escape = F, align = 'c') |>
  kable_classic("hover", full_width = F, position = "center", fixed_thead = T)
```

```{r save-results_cv_BayesA,  include=FALSE}
saveRDS(results_cv_BayesA, "output/results_cv_BayesA.RDS")
```

The object "result_cv" is divided by repetition. In the "result_cv" objects for each repetition, "Rep" is the number of the repetition, "Log" is a diagnostic indicating if the order of the predicted breeding values matches the order of the adjusted means, "Ac" is the prediction accuracy (correlation between the GEBV and adjusted means), and "MSPE" is the mean square prediction error (the lower, the better).

Let's now move on to processing each model. Since this can be time-consuming, I've separated it into parallel processing and each model into each script:

- [*RR-BLUP**](https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava/GWS_RR_BLUP.html)
- [**G-BLUP (additive and additive-dominant)**](https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava/GWS_G-BLUP.html)
- [**Bayes A**](https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava/GWS_BayesA.html)
- [**Bayes B**](https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava/GWS_BayesB.html)
- [**RKHS**](https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava/GWS_RKHS.html)
- [**Random Forest**](https://wevertongomescosta.github.io/Genomic-Selection-for-Drought-Tolerance-Using-Genome-Wide-SNPs-in-Casava/GWS_RF.html)
